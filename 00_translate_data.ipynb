{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "================================================================================\n",
      "KAZAKHSTAN STUDENT DATASET TRANSLATION\n",
      "================================================================================\n",
      "\n",
      "Original data: 121 rows, 32 columns\n",
      "\n",
      "[1/4] Translating column names...\n",
      "✓ Column names translated\n",
      "\n",
      "[2/4] Translating categorical values...\n",
      "✓ Categorical values translated\n",
      "\n",
      "[3/4] Checking for untranslated values...\n",
      "✓ All categorical values translated successfully\n",
      "\n",
      "[4/4] Final processing...\n",
      "✓ Numeric columns converted\n",
      "\n",
      "================================================================================\n",
      "TRANSLATION SUMMARY\n",
      "================================================================================\n",
      "Rows: 121\n",
      "Columns: 32\n",
      "\n",
      "Column names:\n",
      "   1. timestamp\n",
      "   2. email\n",
      "   3. university\n",
      "   4. course_year\n",
      "   5. age\n",
      "   6. gender\n",
      "   7. living_situation\n",
      "   8. family_size\n",
      "   9. mother_education\n",
      "  10. father_education\n",
      "  11. family_income\n",
      "  12. financial_support\n",
      "  13. emotional_support\n",
      "  14. travel_time\n",
      "  15. study_hours_weekly\n",
      "  16. extra_courses\n",
      "  17. academic_failures\n",
      "  18. class_absences\n",
      "  19. internet_access\n",
      "  20. study_space_comfort\n",
      "  21. has_computer\n",
      "  22. health_status\n",
      "  23. physical_activity\n",
      "  24. sleep_hours\n",
      "  25. nursery_school\n",
      "  26. romantic_relationship\n",
      "  27. alcohol_consumption\n",
      "  28. academic_stress\n",
      "  29. peer_support\n",
      "  30. gpa\n",
      "  31. employment_status\n",
      "  32. column_30\n",
      "\n",
      "Data types:\n",
      "object     25\n",
      "int64       4\n",
      "float64     3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Missing values:\n",
      "academic_stress      121\n",
      "column_30            121\n",
      "email                117\n",
      "academic_failures     17\n",
      "nursery_school         6\n",
      "employment_status      1\n",
      "dtype: int64\n",
      "\n",
      "✅ Saved to: /Users/kassi/Data Mining/Final/Code/data/orginal/kz_data_en.csv\n",
      "\n",
      "================================================================================\n",
      "SAMPLE DATA\n",
      "================================================================================\n",
      "             timestamp                          email  \\\n",
      "0  11/21/2025 20:18:41  alinakurakbaeva.007@gmail.com   \n",
      "1  11/21/2025 21:04:21                            NaN   \n",
      "2  11/21/2025 22:43:22                            NaN   \n",
      "\n",
      "                             university course_year  age  gender  \\\n",
      "0         Академия гражданской авиации            2   18  Female   \n",
      "1                                  AITU     Masters   20  Female   \n",
      "2  Медицинский университет Астана (МУА)           4   26  Female   \n",
      "\n",
      "   living_situation  family_size mother_education father_education  ...  \\\n",
      "0  Rented apartment            5           Higher        Secondary  ...   \n",
      "1  Rented apartment            6           Higher           Higher  ...   \n",
      "2  Rented apartment            3       Vocational       Vocational  ...   \n",
      "\n",
      "  physical_activity sleep_hours nursery_school romantic_relationship  \\\n",
      "0            Sports          <5            Yes                    No   \n",
      "1        Music/Arts         5-6            Yes                   Yes   \n",
      "2       No activity         5-6            NaN                   Yes   \n",
      "\n",
      "  alcohol_consumption academic_stress  peer_support   gpa employment_status  \\\n",
      "0               Often             NaN         Never  3.00  Part-time (>20h)   \n",
      "1           Sometimes             NaN     Sometimes  3.93  Part-time (>20h)   \n",
      "2              Rarely             NaN     Sometimes  2.70  Part-time (>20h)   \n",
      "\n",
      "   column_30  \n",
      "0        NaN  \n",
      "1        NaN  \n",
      "2        NaN  \n",
      "\n",
      "[3 rows x 32 columns]\n",
      "\n",
      "================================================================================\n",
      "BASIC STATISTICS\n",
      "================================================================================\n",
      "Gender distribution:\n",
      "gender\n",
      "Female    78\n",
      "Male      43\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Course year distribution:\n",
      "course_year\n",
      "1          13\n",
      "2          20\n",
      "3          22\n",
      "4          59\n",
      "5           2\n",
      "Masters     5\n",
      "Name: count, dtype: int64\n",
      "\n",
      "GPA statistics:\n",
      "count    121.000000\n",
      "mean       3.102810\n",
      "std        0.718537\n",
      "min        0.000000\n",
      "25%        2.900000\n",
      "50%        3.200000\n",
      "75%        3.500000\n",
      "max        4.000000\n",
      "Name: gpa, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "\n",
    "def translate_kazakhstan_dataset(df):\n",
    "    \"\"\"\n",
    "    Переводит датасет казахстанских студентов с русского на английский\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        Исходный датафрейм\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        Переведенный датафрейм\n",
    "    \"\"\"\n",
    "    \n",
    "    # Создать копию\n",
    "    df = df.copy()\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"KAZAKHSTAN STUDENT DATASET TRANSLATION\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nOriginal data: {len(df)} rows, {len(df.columns)} columns\")\n",
    "    \n",
    "    # ==================== 1. ПЕРЕИМЕНОВАТЬ КОЛОНКИ ====================\n",
    "    print(\"\\n[1/4] Translating column names...\")\n",
    "    \n",
    "    column_mapping = {\n",
    "        'Timestamp': 'timestamp',\n",
    "        'Email Address': 'email',\n",
    "        '1. Университет': 'university',\n",
    "        '2. Курс обучения': 'course_year',\n",
    "        '3. Возраст': 'age',\n",
    "        '4. Пол': 'gender',\n",
    "        '5. Место проживания': 'living_situation',\n",
    "        '6. Сколько человек в вашей семье?': 'family_size',\n",
    "        '7. Образование матери': 'mother_education',\n",
    "        '8. Образование отца': 'father_education',\n",
    "        '9. Семейный доход (в тенге в месяц)': 'family_income',\n",
    "        '10. Получаете ли вы финансовую поддержку от семьи?': 'financial_support',\n",
    "        '11. Эмоциональная поддержка семьи в учёбе': 'emotional_support',\n",
    "        '12. Сколько времени занимает дорога в университет': 'travel_time',\n",
    "        '13. Сколько часов в неделю вы занимаетесь самостоятельной учёбой': 'study_hours_weekly',\n",
    "        '14. Посещаете ли вы дополнительные курсы': 'extra_courses',\n",
    "        '15. Были ли у вас академические проблемы (пересдачи, F)': 'academic_failures',\n",
    "        '16. Как часто вы пропускаете пары': 'class_absences',\n",
    "        '17. Есть ли у вас стабильный интернет дома': 'internet_access',\n",
    "        '18. Насколько комфортно ваше место для учёбы': 'study_space_comfort',\n",
    "        '19. Есть ли у вас личный ноутбук/ПК': 'has_computer',\n",
    "        '20. Как вы оцениваете своё здоровье?': 'health_status',\n",
    "        '21. Занимаетесь ли вы спортом/активностями?': 'physical_activity',\n",
    "        '22. Сколько часов сна вы обычно получаете в сутки?': 'sleep_hours',\n",
    "        '23. Посещали ли вы детский сад?': 'nursery_school',\n",
    "        '24. Есть ли у вас романтические отношения?': 'romantic_relationship',\n",
    "        '25. Как часто вы употребляете алкоголь?': 'alcohol_consumption',\n",
    "        '26. Как часто вы испытываете стресс из-за учёбы?': 'academic_stress',\n",
    "        '27. Наличие поддержки от друзей/одногруппников': 'peer_support',\n",
    "        '28. Работаете ли вы?': 'employment_status',\n",
    "        '29. GPA за последний семестр': 'gpa',\n",
    "        'Column 30': 'column_30'\n",
    "    }\n",
    "    \n",
    "    df.rename(columns=column_mapping, inplace=True)\n",
    "    print(\"✓ Column names translated\")\n",
    "    \n",
    "    # ==================== 2. ПЕРЕВЕСТИ ЗНАЧЕНИЯ ====================\n",
    "    print(\"\\n[2/4] Translating categorical values...\")\n",
    "    \n",
    "    # Курс обучения (добавлен \"Магистратура\")\n",
    "    course_mapping = {\n",
    "        '1': '1',\n",
    "        '2': '2', \n",
    "        '3': '3',\n",
    "        '4': '4',\n",
    "        '5': '5',\n",
    "        'Магистратура': 'Masters',\n",
    "        1: '1', 2: '2', 3: '3', 4: '4', 5: '5'\n",
    "    }\n",
    "    if 'course_year' in df.columns:\n",
    "        df['course_year'] = df['course_year'].astype(str).map(course_mapping)\n",
    "    \n",
    "    # Пол\n",
    "    gender_mapping = {'М': 'Male', 'Ж': 'Female'}\n",
    "    if 'gender' in df.columns:\n",
    "        df['gender'] = df['gender'].map(gender_mapping)\n",
    "    \n",
    "    # Место проживания\n",
    "    living_mapping = {\n",
    "        'Съёмная квартира': 'Rented apartment',\n",
    "        'С родителями/Родственники': 'With parents',\n",
    "        'Общежитие': 'Dormitory',\n",
    "        'Другое': 'Other'\n",
    "    }\n",
    "    if 'living_situation' in df.columns:\n",
    "        df['living_situation'] = df['living_situation'].map(living_mapping)\n",
    "    \n",
    "    # Образование\n",
    "    education_mapping = {\n",
    "        'Среднее': 'Secondary',\n",
    "        'Средне-специальное': 'Vocational',\n",
    "        'Высшее': 'Higher',\n",
    "        'Магистратура и выше': 'Masters+'\n",
    "    }\n",
    "    if 'mother_education' in df.columns:\n",
    "        df['mother_education'] = df['mother_education'].map(education_mapping)\n",
    "    if 'father_education' in df.columns:\n",
    "        df['father_education'] = df['father_education'].map(education_mapping)\n",
    "    \n",
    "    # Семейный доход\n",
    "    income_mapping = {\n",
    "        'Низкий (<200 000)': 'Low',\n",
    "        'Средний (200 000–400 000)': 'Average',\n",
    "        'Выше среднего (400 001–700 000)': 'Above average',\n",
    "        'Высокий (>700 000)': 'High'\n",
    "    }\n",
    "    if 'family_income' in df.columns:\n",
    "        df['family_income'] = df['family_income'].map(income_mapping)\n",
    "    \n",
    "    # Финансовая поддержка\n",
    "    support_mapping = {\n",
    "        'Да': 'Yes',\n",
    "        'Нет': 'No',\n",
    "        'Частично': 'Partially',\n",
    "        'Полностью': 'Fully'\n",
    "    }\n",
    "    if 'financial_support' in df.columns:\n",
    "        df['financial_support'] = df['financial_support'].map(support_mapping)\n",
    "    \n",
    "    # Эмоциональная поддержка\n",
    "    frequency_mapping = {\n",
    "        'Никогда': 'Never',\n",
    "        'Редко': 'Rarely',\n",
    "        'Иногда': 'Sometimes',\n",
    "        'Часто': 'Often',\n",
    "        'Всегда': 'Always'\n",
    "    }\n",
    "    if 'emotional_support' in df.columns:\n",
    "        df['emotional_support'] = df['emotional_support'].map(frequency_mapping)\n",
    "    \n",
    "    # Время в дороге\n",
    "    travel_mapping = {\n",
    "        '<15 мин': '<15 min',\n",
    "        '15–30 мин': '15-30 min',\n",
    "        '30–60 мин': '30-60 min',\n",
    "        '>1 часа': '>60 min'\n",
    "    }\n",
    "    if 'travel_time' in df.columns:\n",
    "        df['travel_time'] = df['travel_time'].map(travel_mapping)\n",
    "    \n",
    "    # Часы учёбы в неделю\n",
    "    study_mapping = {\n",
    "        '<5': '<5',\n",
    "        '5–10': '5-10',\n",
    "        '10–20': '10-20',\n",
    "        '>20': '>20'\n",
    "    }\n",
    "    if 'study_hours_weekly' in df.columns:\n",
    "        df['study_hours_weekly'] = df['study_hours_weekly'].map(study_mapping)\n",
    "    \n",
    "    # Да/Нет вопросы\n",
    "    yes_no_mapping = {'Да': 'Yes', 'Нет': 'No'}\n",
    "    yes_no_columns = ['extra_courses', 'nursery_school', 'romantic_relationship']\n",
    "    for col in yes_no_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].map(yes_no_mapping)\n",
    "    \n",
    "    # Пропуски пар\n",
    "    absences_mapping = {\n",
    "        'Никогда': 'Never',\n",
    "        'Почти никогда': 'Almost never',\n",
    "        'Редко': 'Rarely',\n",
    "        'Иногда': 'Sometimes',\n",
    "        'Часто': 'Often',\n",
    "        'Очень часто': 'Very often'\n",
    "    }\n",
    "    if 'class_absences' in df.columns:\n",
    "        df['class_absences'] = df['class_absences'].map(absences_mapping)\n",
    "    \n",
    "    # Интернет\n",
    "    internet_mapping = {\n",
    "        'Да': 'Yes',\n",
    "        'Нет': 'No',\n",
    "        'Иногда': 'Sometimes',\n",
    "        'Редко': 'Rarely',\n",
    "        'Всегда': 'Always'\n",
    "    }\n",
    "    if 'internet_access' in df.columns:\n",
    "        df['internet_access'] = df['internet_access'].map(internet_mapping)\n",
    "    \n",
    "    # Наличие компьютера\n",
    "    computer_mapping = {\n",
    "        'Да': 'Yes',\n",
    "        'Нет': 'No',\n",
    "        'Пользуюсь общим': 'Shared'\n",
    "    }\n",
    "    if 'has_computer' in df.columns:\n",
    "        df['has_computer'] = df['has_computer'].map(computer_mapping)\n",
    "    \n",
    "    # Физическая активность (complex - может быть multiple)\n",
    "    # Оставляем как есть для дальнейшей обработки или можем разбить\n",
    "    activity_keywords = {\n",
    "        'Спорт': 'Sports',\n",
    "        'Музыка/творчество': 'Music/Arts',\n",
    "        'Волонтёрство': 'Volunteering',\n",
    "        'Кружки/хобби': 'Clubs/Hobbies',\n",
    "        'Нет активности': 'No activity'\n",
    "    }\n",
    "    if 'physical_activity' in df.columns:\n",
    "        def translate_activity(val):\n",
    "            if pd.isna(val):\n",
    "                return val\n",
    "            val_str = str(val)\n",
    "            for rus, eng in activity_keywords.items():\n",
    "                val_str = val_str.replace(rus, eng)\n",
    "            return val_str\n",
    "        df['physical_activity'] = df['physical_activity'].apply(translate_activity)\n",
    "    \n",
    "    # Часы сна\n",
    "    sleep_mapping = {\n",
    "        '<5': '<5',\n",
    "        '5–6': '5-6',\n",
    "        '6–7': '6-7',\n",
    "        '7–8': '7-8',\n",
    "        '>8': '>8'\n",
    "    }\n",
    "    if 'sleep_hours' in df.columns:\n",
    "        df['sleep_hours'] = df['sleep_hours'].map(sleep_mapping)\n",
    "    \n",
    "    # Не помню\n",
    "    memory_mapping = {\n",
    "        'Да': 'Yes',\n",
    "        'Нет': 'No',\n",
    "        'Не помню': 'Don\\'t remember'\n",
    "    }\n",
    "    if 'nursery_school' in df.columns:\n",
    "        df['nursery_school'] = df['nursery_school'].apply(\n",
    "            lambda x: memory_mapping.get(x, x) if pd.notna(x) else x\n",
    "        )\n",
    "    \n",
    "    # Алкоголь\n",
    "    alcohol_mapping = {\n",
    "        'Никогда': 'Never',\n",
    "        'Редко': 'Rarely',\n",
    "        'Иногда': 'Sometimes',\n",
    "        'Часто': 'Often'\n",
    "    }\n",
    "    if 'alcohol_consumption' in df.columns:\n",
    "        df['alcohol_consumption'] = df['alcohol_consumption'].map(alcohol_mapping)\n",
    "    \n",
    "    # Стресс\n",
    "    if 'academic_stress' in df.columns:\n",
    "        df['academic_stress'] = df['academic_stress'].map(frequency_mapping)\n",
    "    \n",
    "    # Поддержка друзей\n",
    "    if 'peer_support' in df.columns:\n",
    "        df['peer_support'] = df['peer_support'].map(frequency_mapping)\n",
    "    \n",
    "    # Работа\n",
    "    work_mapping = {\n",
    "        'Нет': 'No',\n",
    "        'Подработка (меньше 20 часов в неделю)': 'Part-time (<20h)',\n",
    "        'Да (больше 20 часов в неделю)': 'Part-time (>20h)',\n",
    "        'Да (меньше 20 часов в неделю)': 'Part-time (<20h)'\n",
    "    }\n",
    "    if 'employment_status' in df.columns:\n",
    "        df['employment_status'] = df['employment_status'].map(work_mapping)\n",
    "    \n",
    "    print(\"✓ Categorical values translated\")\n",
    "    \n",
    "    # ==================== 3. ПРОВЕРКА ====================\n",
    "    print(\"\\n[3/4] Checking for untranslated values...\")\n",
    "    \n",
    "    untranslated = []\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            # Проверить кириллицу\n",
    "            has_cyrillic = df[col].astype(str).str.contains('[а-яА-Я]', na=False, regex=True).any()\n",
    "            if has_cyrillic and col not in ['timestamp', 'email', 'university']:\n",
    "                unique_vals = df[col][df[col].notna()].unique()\n",
    "                cyrillic_vals = [v for v in unique_vals if isinstance(v, str) and any(c.lower() in 'абвгдеёжзийклмнопрстуфхцчшщъыьэюя' for c in v)]\n",
    "                if cyrillic_vals:\n",
    "                    untranslated.append({\n",
    "                        'column': col,\n",
    "                        'values': cyrillic_vals[:5]  # Показать первые 5\n",
    "                    })\n",
    "    \n",
    "    if untranslated:\n",
    "        print(\"\\n⚠️  Found untranslated values:\")\n",
    "        for item in untranslated:\n",
    "            print(f\"   • {item['column']}: {item['values']}\")\n",
    "    else:\n",
    "        print(\"✓ All categorical values translated successfully\")\n",
    "    \n",
    "    # ==================== 4. ФИНАЛЬНАЯ ОБРАБОТКА ====================\n",
    "    print(\"\\n[4/4] Final processing...\")\n",
    "    \n",
    "    # Конвертировать числовые колонки\n",
    "    numeric_cols = ['age', 'family_size', 'academic_failures', 'study_space_comfort', \n",
    "                    'health_status', 'gpa']\n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    print(\"✓ Numeric columns converted\")\n",
    "    \n",
    "    # ==================== SUMMARY ====================\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"TRANSLATION SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Rows: {len(df)}\")\n",
    "    print(f\"Columns: {len(df.columns)}\")\n",
    "    print(f\"\\nColumn names:\")\n",
    "    for i, col in enumerate(df.columns, 1):\n",
    "        print(f\"  {i:2d}. {col}\")\n",
    "    \n",
    "    print(f\"\\nData types:\")\n",
    "    print(df.dtypes.value_counts())\n",
    "    \n",
    "    print(f\"\\nMissing values:\")\n",
    "    missing = df.isnull().sum()\n",
    "    missing = missing[missing > 0].sort_values(ascending=False)\n",
    "    if len(missing) > 0:\n",
    "        print(missing)\n",
    "    else:\n",
    "        print(\"  No missing values\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# ==================== ИСПОЛЬЗОВАНИЕ ====================\n",
    "if __name__ == \"__main__\":\n",
    "    # Пример использования\n",
    "    \n",
    "    # 1. Загрузить данные\n",
    "    print(\"Loading data...\")\n",
    "    df = pd.read_csv('/Users/kassi/Data Mining/Final/Code/data/orginal/kz_data.csv')\n",
    "    \n",
    "    # 2. Перевести\n",
    "    df_english = translate_kazakhstan_dataset(df)\n",
    "    \n",
    "    # 3. Сохранить\n",
    "    output_file = '/Users/kassi/Data Mining/Final/Code/data/orginal/kz_data_en.csv'\n",
    "    df_english.to_csv(output_file, index=False, encoding='utf-8')\n",
    "    print(f\"\\n✅ Saved to: {output_file}\")\n",
    "    \n",
    "    # 4. Показать примеры\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SAMPLE DATA\")\n",
    "    print(\"=\"*80)\n",
    "    print(df_english.head(3))\n",
    "    \n",
    "    # 5. Базовая статистика\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"BASIC STATISTICS\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Gender distribution:\")\n",
    "    print(df_english['gender'].value_counts())\n",
    "    print(f\"\\nCourse year distribution:\")\n",
    "    print(df_english['course_year'].value_counts().sort_index())\n",
    "    print(f\"\\nGPA statistics:\")\n",
    "    print(df_english['gpa'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "================================================================================\n",
      "CLEANING ENCODED DATASET\n",
      "================================================================================\n",
      "\n",
      "Original shape: (121, 32)\n",
      "Original columns: 32\n",
      "\n",
      "[1/4] Removing timestamp columns...\n",
      "   No timestamp columns found\n",
      "\n",
      "[2/4] Removing email columns...\n",
      "   No email columns found\n",
      "\n",
      "[3/4] Checking university columns...\n",
      "   No university columns found\n",
      "\n",
      "[4/4] Removing other unnecessary columns...\n",
      "   ✓ Removed empty 'column_30'\n",
      "   Removing original columns: ['timestamp', 'email']\n",
      "   ✓ Removed 2 original columns\n",
      "\n",
      "================================================================================\n",
      "CLEANING SUMMARY\n",
      "================================================================================\n",
      "Original shape: (121, 32)\n",
      "Cleaned shape:  (121, 29)\n",
      "Columns removed: 3\n",
      "\n",
      "✅ Cleaning complete!\n",
      "   Rows: 121\n",
      "   Columns: 29\n",
      "\n",
      "================================================================================\n",
      "COLUMN GROUPS\n",
      "================================================================================\n",
      "\n",
      "Demographics (5):\n",
      "  • university\n",
      "  • course_year\n",
      "  • age\n",
      "  • gender\n",
      "  • living_situation\n",
      "\n",
      "Family (6):\n",
      "  • family_size\n",
      "  • mother_education\n",
      "  • father_education\n",
      "  • family_income\n",
      "  • financial_support\n",
      "  • emotional_support\n",
      "\n",
      "Academic (5):\n",
      "  • study_hours_weekly\n",
      "  • extra_courses\n",
      "  • academic_failures\n",
      "  • class_absences\n",
      "  • travel_time\n",
      "\n",
      "Environment (3):\n",
      "  • internet_access\n",
      "  • study_space_comfort\n",
      "  • has_computer\n",
      "\n",
      "Health/Lifestyle (4):\n",
      "  • health_status\n",
      "  • physical_activity\n",
      "  • sleep_hours\n",
      "  • nursery_school\n",
      "\n",
      "Social (4):\n",
      "  • romantic_relationship\n",
      "  • alcohol_consumption\n",
      "  • academic_stress\n",
      "  • peer_support\n",
      "\n",
      "Employment (1):\n",
      "  • employment_status\n",
      "\n",
      "Target (1):\n",
      "  • gpa\n",
      "\n",
      "Encoded Features (25):\n",
      "  academic: 2 features\n",
      "  alcohol: 1 features\n",
      "  class: 1 features\n",
      "  course: 1 features\n",
      "  emotional: 1 features\n",
      "  employment: 1 features\n",
      "  extra: 1 features\n",
      "  family: 2 features\n",
      "  father: 1 features\n",
      "  financial: 1 features\n",
      "  has: 1 features\n",
      "  health: 1 features\n",
      "  internet: 1 features\n",
      "  living: 1 features\n",
      "  mother: 1 features\n",
      "  nursery: 1 features\n",
      "  peer: 1 features\n",
      "  physical: 1 features\n",
      "  romantic: 1 features\n",
      "  sleep: 1 features\n",
      "  study: 2 features\n",
      "  travel: 1 features\n",
      "\n",
      "================================================================================\n",
      "SELECTING FEATURES FOR MODELING\n",
      "================================================================================\n",
      "\n",
      "Selected 7 features for modeling\n",
      "  • Basic features: 2\n",
      "  • Encoded features: 5\n",
      "\n",
      "================================================================================\n",
      "SAVING CLEANED DATA\n",
      "================================================================================\n",
      "✓ Saved: /Users/kassi/Data Mining/Final/Code/data/orginal/kz_data_en.csv\n",
      "✓ Saved: /Users/kassi/Data Mining/Final/Code/data/orginal/kz_data_modeling.csv.csv\n",
      "\n",
      "✅ All done!\n",
      "   Clean data: (121, 29)\n",
      "   Modeling data: (121, 7)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def clean_encoded_dataset(df):\n",
    "    \"\"\"\n",
    "    Удаляет ненужные колонки из датасета после encoding\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        Датафрейм с лишними колонками\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        Очищенный датафрейм\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"CLEANING ENCODED DATASET\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nOriginal shape: {df.shape}\")\n",
    "    print(f\"Original columns: {len(df.columns)}\")\n",
    "    \n",
    "    # Создать копию\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # ==================== 1. УДАЛИТЬ TIMESTAMP КОЛОНКИ ====================\n",
    "    print(\"\\n[1/4] Removing timestamp columns...\")\n",
    "    \n",
    "    # Найти все колонки начинающиеся с timestamp_\n",
    "    timestamp_cols = [col for col in df_clean.columns if col.startswith('timestamp_')]\n",
    "    \n",
    "    if timestamp_cols:\n",
    "        print(f\"   Found {len(timestamp_cols)} timestamp columns\")\n",
    "        df_clean = df_clean.drop(columns=timestamp_cols)\n",
    "        print(f\"   ✓ Removed {len(timestamp_cols)} columns\")\n",
    "    else:\n",
    "        print(\"   No timestamp columns found\")\n",
    "    \n",
    "    # ==================== 2. УДАЛИТЬ EMAIL КОЛОНКИ ====================\n",
    "    print(\"\\n[2/4] Removing email columns...\")\n",
    "    \n",
    "    # Найти все колонки начинающиеся с email_\n",
    "    email_cols = [col for col in df_clean.columns if col.startswith('email_')]\n",
    "    \n",
    "    if email_cols:\n",
    "        print(f\"   Found {len(email_cols)} email columns\")\n",
    "        df_clean = df_clean.drop(columns=email_cols)\n",
    "        print(f\"   ✓ Removed {len(email_cols)} columns\")\n",
    "    else:\n",
    "        print(\"   No email columns found\")\n",
    "    \n",
    "    # ==================== 3. УДАЛИТЬ UNIVERSITY КОЛОНКИ (опционально) ====================\n",
    "    print(\"\\n[3/4] Checking university columns...\")\n",
    "    \n",
    "    # Найти все колонки начинающиеся с university_\n",
    "    university_cols = [col for col in df_clean.columns if col.startswith('university_')]\n",
    "    \n",
    "    if university_cols:\n",
    "        print(f\"   Found {len(university_cols)} university one-hot encoded columns\")\n",
    "        print(f\"   Note: These are one-hot encoded universities - keep or remove?\")\n",
    "        # Можете раскомментировать если хотите удалить:\n",
    "        # df_clean = df_clean.drop(columns=university_cols)\n",
    "        # print(f\"   ✓ Removed {len(university_cols)} columns\")\n",
    "    else:\n",
    "        print(\"   No university columns found\")\n",
    "    \n",
    "    # ==================== 4. УДАЛИТЬ ДРУГИЕ НЕНУЖНЫЕ КОЛОНКИ ====================\n",
    "    print(\"\\n[4/4] Removing other unnecessary columns...\")\n",
    "    \n",
    "    # Удалить column_30 если пустая\n",
    "    if 'column_30' in df_clean.columns:\n",
    "        if df_clean['column_30'].isna().all():\n",
    "            df_clean = df_clean.drop(columns=['column_30'])\n",
    "            print(\"   ✓ Removed empty 'column_30'\")\n",
    "    \n",
    "    # Удалить оригинальные timestamp и email если нужно\n",
    "    drop_cols = []\n",
    "    \n",
    "    # Timestamp - обычно не нужен для анализа\n",
    "    if 'timestamp' in df_clean.columns:\n",
    "        drop_cols.append('timestamp')\n",
    "    \n",
    "    # Email - конфиденциальная информация\n",
    "    if 'email' in df_clean.columns:\n",
    "        drop_cols.append('email')\n",
    "    \n",
    "    if drop_cols:\n",
    "        print(f\"   Removing original columns: {drop_cols}\")\n",
    "        df_clean = df_clean.drop(columns=drop_cols)\n",
    "        print(f\"   ✓ Removed {len(drop_cols)} original columns\")\n",
    "    \n",
    "    # ==================== SUMMARY ====================\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"CLEANING SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Original shape: {df.shape}\")\n",
    "    print(f\"Cleaned shape:  {df_clean.shape}\")\n",
    "    print(f\"Columns removed: {len(df.columns) - len(df_clean.columns)}\")\n",
    "    \n",
    "    print(f\"\\n✅ Cleaning complete!\")\n",
    "    print(f\"   Rows: {len(df_clean)}\")\n",
    "    print(f\"   Columns: {len(df_clean.columns)}\")\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "\n",
    "def get_column_groups(df):\n",
    "    \"\"\"\n",
    "    Группирует колонки по категориям для лучшего понимания\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"COLUMN GROUPS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    groups = {\n",
    "        'Demographics': ['university', 'course_year', 'age', 'gender', 'living_situation'],\n",
    "        'Family': ['family_size', 'mother_education', 'father_education', \n",
    "                   'family_income', 'financial_support', 'emotional_support'],\n",
    "        'Academic': ['study_hours_weekly', 'extra_courses', 'academic_failures', \n",
    "                     'class_absences', 'travel_time'],\n",
    "        'Environment': ['internet_access', 'study_space_comfort', 'has_computer'],\n",
    "        'Health/Lifestyle': ['health_status', 'physical_activity', 'sleep_hours', 'nursery_school'],\n",
    "        'Social': ['romantic_relationship', 'alcohol_consumption', 'academic_stress', 'peer_support'],\n",
    "        'Employment': ['employment_status'],\n",
    "        'Target': ['gpa']\n",
    "    }\n",
    "    \n",
    "    # Найти какие колонки есть\n",
    "    for group_name, cols in groups.items():\n",
    "        existing = [col for col in cols if col in df.columns]\n",
    "        if existing:\n",
    "            print(f\"\\n{group_name} ({len(existing)}):\")\n",
    "            for col in existing:\n",
    "                print(f\"  • {col}\")\n",
    "    \n",
    "    # Encoded колонки\n",
    "    encoded_cols = [col for col in df.columns if '_' in col and \n",
    "                    not col.startswith(('timestamp_', 'email_', 'column_'))]\n",
    "    \n",
    "    if encoded_cols:\n",
    "        print(f\"\\nEncoded Features ({len(encoded_cols)}):\")\n",
    "        # Группировать по префиксу\n",
    "        prefixes = {}\n",
    "        for col in encoded_cols:\n",
    "            prefix = col.split('_')[0]\n",
    "            if prefix not in prefixes:\n",
    "                prefixes[prefix] = []\n",
    "            prefixes[prefix].append(col)\n",
    "        \n",
    "        for prefix, cols in sorted(prefixes.items()):\n",
    "            print(f\"  {prefix}: {len(cols)} features\")\n",
    "\n",
    "\n",
    "def select_features_for_modeling(df):\n",
    "    \"\"\"\n",
    "    Выбирает только нужные колонки для моделирования\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SELECTING FEATURES FOR MODELING\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Базовые колонки (не encoded)\n",
    "    basic_features = [\n",
    "        'course_year', 'age', 'family_size', 'study_space_comfort',\n",
    "        'health_status', 'academic_failures', 'gpa'\n",
    "    ]\n",
    "    \n",
    "    # Encoded колонки (только полезные)\n",
    "    encoded_prefixes = [\n",
    "        'gender_', 'living_situation_', 'mother_education_', 'father_education_',\n",
    "        'family_income_', 'financial_support_', 'emotional_support_',\n",
    "        'travel_time_', 'study_hours_weekly_', 'extra_courses_',\n",
    "        'class_absences_', 'internet_access_', 'has_computer_',\n",
    "        'physical_activity_', 'sleep_hours_', 'nursery_school_',\n",
    "        'romantic_relationship_', 'alcohol_consumption_', 'academic_stress_',\n",
    "        'peer_support_', 'employment_status_'\n",
    "    ]\n",
    "    \n",
    "    # Собрать все нужные колонки\n",
    "    selected_cols = []\n",
    "    \n",
    "    # Базовые\n",
    "    for col in basic_features:\n",
    "        if col in df.columns:\n",
    "            selected_cols.append(col)\n",
    "    \n",
    "    # Encoded\n",
    "    for prefix in encoded_prefixes:\n",
    "        matching = [col for col in df.columns if col.startswith(prefix)]\n",
    "        selected_cols.extend(matching)\n",
    "    \n",
    "    print(f\"\\nSelected {len(selected_cols)} features for modeling\")\n",
    "    print(f\"  • Basic features: {len([c for c in selected_cols if '_' not in c])}\")\n",
    "    print(f\"  • Encoded features: {len([c for c in selected_cols if '_' in c])}\")\n",
    "    \n",
    "    # Создать новый датафрейм\n",
    "    df_modeling = df[selected_cols].copy()\n",
    "    \n",
    "    return df_modeling\n",
    "\n",
    "\n",
    "# ==================== ИСПОЛЬЗОВАНИЕ ====================\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # 1. Загрузить данные\n",
    "    print(\"Loading data...\")\n",
    "    df = pd.read_csv('/Users/kassi/Data Mining/Final/Code/data/orginal/kz_data_en.csv')\n",
    "    \n",
    "    # 2. Очистить\n",
    "    df_clean = clean_encoded_dataset(df)\n",
    "    \n",
    "    # 3. Показать группы колонок\n",
    "    get_column_groups(df_clean)\n",
    "    \n",
    "    # 4. Выбрать только нужные для моделирования\n",
    "    df_modeling = select_features_for_modeling(df_clean)\n",
    "    \n",
    "    # 5. Сохранить\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SAVING CLEANED DATA\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Полная очищенная версия\n",
    "    df_clean.to_csv('/Users/kassi/Data Mining/Final/Code/data/orginal/kz_data_en.csv', index=False)\n",
    "    print(\"✓ Saved: /Users/kassi/Data Mining/Final/Code/data/orginal/kz_data_en.csv\")\n",
    "    \n",
    "    # Версия только для моделирования\n",
    "    df_modeling.to_csv('/Users/kassi/Data Mining/Final/Code/data/orginal/kz_data_modeling.csv.csv', index=False)\n",
    "    print(\"✓ Saved: /Users/kassi/Data Mining/Final/Code/data/orginal/kz_data_modeling.csv.csv\")\n",
    "    \n",
    "    print(f\"\\n✅ All done!\")\n",
    "    print(f\"   Clean data: {df_clean.shape}\")\n",
    "    print(f\"   Modeling data: {df_modeling.shape}\")\n",
    "\n",
    "\n",
    "# ==================== БЫСТРОЕ РЕШЕНИЕ ====================\n",
    "def quick_clean(input_file, output_file):\n",
    "    \"\"\"\n",
    "    Быстрая очистка - просто удалить timestamp_ и email_ колонки\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(input_file)\n",
    "    \n",
    "    # Удалить timestamp_ и email_ колонки\n",
    "    cols_to_drop = [col for col in df.columns \n",
    "                    if col.startswith('timestamp_') or col.startswith('email_')]\n",
    "    \n",
    "    df_clean = df.drop(columns=cols_to_drop)\n",
    "    \n",
    "    # Удалить пустые колонки\n",
    "    df_clean = df_clean.dropna(axis=1, how='all')\n",
    "    \n",
    "    df_clean.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"✅ Cleaned!\")\n",
    "    print(f\"   Original: {len(df.columns)} columns\")\n",
    "    print(f\"   Cleaned:  {len(df_clean.columns)} columns\")\n",
    "    print(f\"   Removed:  {len(cols_to_drop)} columns\")\n",
    "    print(f\"   Saved to: {output_file}\")\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "\n",
    "# Использовать так:\n",
    "# df_clean = quick_clean('your_file.csv', 'cleaned_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foreign_data CSV обновлён\n"
     ]
    }
   ],
   "source": [
    "# foreign_data = pd.read_csv('/Users/kassi/Data Mining/Final/Code/data/orginal/student_portuguese.csv')\n",
    "\n",
    "# # Создаём новую колонку GPA в диапазоне 0-4\n",
    "# import numpy as np\n",
    "\n",
    "# def grade_to_gpa(score):\n",
    "#     if score >= 18:\n",
    "#         return 4.0\n",
    "#     elif score >= 17:\n",
    "#         return 3.67\n",
    "#     elif score >= 16:\n",
    "#         return 3.33\n",
    "#     elif score >= 15:\n",
    "#         return 3.0\n",
    "#     elif score >= 14:\n",
    "#         return 2.67\n",
    "#     elif score >= 13:\n",
    "#         return 2.33\n",
    "#     elif score >= 12:\n",
    "#         return 2.0\n",
    "#     elif score >= 10:\n",
    "#         return 1.0\n",
    "#     else:\n",
    "#         return 0.0\n",
    "\n",
    "# # Применяем ко всей колонке\n",
    "# foreign_data['final_grade'] = foreign_data['final_grade'].apply(grade_to_gpa)\n",
    "\n",
    "\n",
    "# # Сохраняем обновлённый CSV\n",
    "# foreign_data.to_csv('/Users/kassi/Data Mining/Final/Code/data/orginal/student_portuguese.csv', index=False)\n",
    "\n",
    "# print(\"foreign_data CSV обновлён\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
